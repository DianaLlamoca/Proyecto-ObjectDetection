{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3rZ4VGUhA6Z"
   },
   "outputs": [],
   "source": [
    "#Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,LeakyReLU, BatchNormalization\n",
    "\n",
    "\n",
    "#Cargamos las clases del dataset y le asignamos un número. Se guardán en forma de clave, valor en un diccionario.\n",
    "clases=[\"cat\",\"chicken\",\"cow\",\"dog\",\"fox\",\"goat\",\"horse\",\"person\",\"racoon\",\"skunk\"]\n",
    "etiquetas={clase:ide for ide,clase in enumerate(clases)}\n",
    "\n",
    "#Ahora, se crea una función para procesar las imágenes, ya que se hará un 'reshape' para que se tenga la misma forma en todas las img.\n",
    "def Imagenes(path_img):\n",
    "    #Se lee la imagen\n",
    "    #Imagen=cv2.imread(path_img)\n",
    "    Imagen=Image.open(path_img).convert(\"RGB\") #Leemos las imágenes, pero en RGB\n",
    "\n",
    "    #Finalmente, se hace el resize para que cada imagen tenga la misma forma (se mantienen los 3 canales RGB)\n",
    "    Imagen=Imagen.resize((224,224))\n",
    "\n",
    "    #Lo convertimos a un arreglo de numpy\n",
    "    Imagen=np.array(Imagen)\n",
    "\n",
    "    return Imagen\n",
    "\n",
    "#Debido a que las anotaciones del etiquetado están en un archivo XML, se procederá a extraer la información\n",
    "#necesaria, como los bordes de las anotaciones y su clase correspondiente de la imagen. Para ello, se hará uso\n",
    "#de la librería xml.etree.ElementTree\n",
    "def Data(root_path):\n",
    "    #Creamos dos listas, una donde se almacenará la imagen y la otra contendrán las variables objetivos (bordes de las anotaciones, clase)\n",
    "    imagenes=[]\n",
    "    targets=[]\n",
    "\n",
    "    clase=[]\n",
    "\n",
    "    #Obtenemos las rutas de solo los archivos xml para la lectura de los mismos\n",
    "    xml_rutas=sorted([os.path.join(root_path,direct) for direct in os.listdir(root_path) if direct.endswith(\".xml\")])\n",
    "\n",
    "\n",
    "    #Ya que se tienen las rutas de los archivos xml, se procederá a obtener la información necesaria de cada uno de ellos\n",
    "    #Se recorre cada uno de los archivos xml\n",
    "    for xml in xml_rutas:\n",
    "        #Sin embargo, antes de proceder con la lectura de los xml, debemos aprovechar que los nombres de las imgs son iguales al de los xlm,\n",
    "        #así que también las leemos, ya que deben ser almacenadas para entrenar a la red neuronal\n",
    "        img_ruta=xml.replace(\".xml\",\".jpg\") #cambiamos el .xml a .jpg para tener las rutas de cada imagen\n",
    "\n",
    "        #Ya que se tiene la ruta de la imagen, la mandamos a procesar para realizar el resize mediante la función que creamos al inicio\n",
    "        img=Imagenes(img_ruta)\n",
    "\n",
    "        #Se lee el archivo xml\n",
    "        arc_xml=ET.parse(xml)\n",
    "\n",
    "        #Ahora, se obtiene el elemento \"raíz\" de ese archivo, para a partir de él iterar los demás elementos en el archivo xml\n",
    "        elem_root=arc_xml.getroot()\n",
    "\n",
    "        #Se procederá con la iteración,a partir del elemento raíz, en busca de la información que se quiere obtener\n",
    "        #Se selecciona el elemento hijo \"object\" del elemento root, pues aquí se encuentra la información que buscamos\n",
    "        for elem in elem_root.findall('object'):\n",
    "\n",
    "            #Ya que nos situamos en \"object\", obtenemos la clase de la imagen, que está ubicada en \"name\" (en el archivo xml)\n",
    "            etiq=elem.find('name').text\n",
    "\n",
    "            #Sin embargo, lo que se quiere obtener es el valor numérico de dicha clase, entonces usamos el diccionario que creamos al inicio\n",
    "            etiq_ide=etiquetas.get(etiq)\n",
    "\n",
    "            #Obtenemos el ancho y alto de cada imagen\n",
    "            width=int(elem_root.find('size').find('width').text)\n",
    "            height=int(elem_root.find('size').find('height').text)\n",
    "\n",
    "            #Obtenemos, ahora, las posiciones de los bordes donde se encuentran los objetos en las imágenes\n",
    "            #Para ello, nos situamos dentro de \"bndbox\", que a su vez se encuentra dentro de \"object\"\n",
    "            box=elem.find('bndbox')\n",
    "\n",
    "            #Procedemos a obtener las posiciones correspondientes y se divide, pues se hizo un resize de la imagen\n",
    "            xmin=int(int(box.find('xmin').text)/(width/224))\n",
    "            ymin=int(int(box.find('ymin').text)/(height/224))\n",
    "            xmax=int(int(box.find('xmax').text)/(width/224))\n",
    "            ymax=int(int(box.find('ymax').text)/(height/224))\n",
    "\n",
    "            #Ahora, guardamos cada uno de los datos en las listas \"imagenes\",\"targets\", en donde mencionamos que serían almacenados\n",
    "            targets.append([xmin,ymin,xmax,ymax])\n",
    "            imagenes.append(img)\n",
    "            clase.append(etiq_ide)\n",
    "\n",
    "    return np.array(imagenes),np.array(targets),np.array(clase)\n",
    "\n",
    "#Ya que se crearon las funciones que nos ayudarán con la lectura de los datos, cargamos las rutas donde se\n",
    "#encuentran los datos de train y test para mandar a llamar a cada una de las funciones\n",
    "train_path= \"C:/Users/DIANA/PyCharm/INTENTO/train\"\n",
    "test_path= \"C:/Users/DIANA/PyCharm/INTENTO/test\"\n",
    "\n",
    "#Ahora sí, se manda a llamar a las funciones para que operen sobre cada una de los archivos e imágenes\n",
    "x_train,y_train,ytrain_clase=Data(train_path)\n",
    "\n",
    "x_test,y_test,ytest_clase=Data(test_path)\n",
    "#Notar lo que valores de los píxeles aún están entre 0-255 (la normalización se hará en la capa de entrada de la red)\n",
    "\n",
    "#Ya que la data está preprocesada, se procederá a crear la arquitectura de la red\n",
    "#Debido a que la detección de objetos necesita de clasificación y regresión para obtener los bounding boxes, se creará, primero,\n",
    "#la arquitectura compartida\n",
    "\n",
    "data_input=(224,224,3) #Pues las imágenes son de esa dimensión\n",
    "input_layer=tensorflow.keras.layers.Input(data_input) #Esta es la capa de entrada\n",
    "\n",
    "#Se crean, ahora, las capas bases\n",
    "#La primera capa se encargará de realizar la normalización y luego las capas para la extracción de características\n",
    "capas_base=layers.Rescaling(scale=1./255,name=\"capa_base1\")(input_layer)\n",
    "capas_base=layers.Conv2D(32,3,padding=\"same\",activation=\"relu\",name=\"capa_base2\")(capas_base)\n",
    "capas_base=layers.MaxPooling2D(name=\"capa_base3\")(capas_base)\n",
    "capas_base=layers.BatchNormalization()(capas_base)\n",
    "capas_base=layers.Conv2D(32,3,padding=\"same\",activation=\"relu\",name=\"capa_base4\")(capas_base)\n",
    "capas_base=layers.BatchNormalization()(capas_base)\n",
    "capas_base=layers.Conv2D(32,3,padding=\"same\",activation=\"relu\")(capas_base)\n",
    "capas_base=layers.MaxPooling2D(name=\"capa_base5\")(capas_base)\n",
    "capas_base=layers.BatchNormalization()(capas_base)\n",
    "capas_base=layers.Conv2D(32,3,padding=\"same\",activation=\"relu\",name=\"capa_base6\")(capas_base)\n",
    "capas_base=layers.MaxPooling2D(name=\"capa_base7\")(capas_base)\n",
    "capas_base=layers.BatchNormalization()(capas_base)\n",
    "capas_base=layers.Conv2D(32,3,padding=\"same\",activation=\"relu\",name=\"capa_base8\")(capas_base)\n",
    "capas_base=layers.MaxPooling2D(name=\"capa_base9\")(capas_base)\n",
    "capas_base=layers.Flatten(name=\"capa_base10\")(capas_base) #La capa de entrada a la red full connected (acá se obtienen vectores)\n",
    "\n",
    "#Ahora, a partir de la capa de Flatten, se crearán las capas para la clasificación\n",
    "clasificacion=layers.Dense(128,activation=\"relu\",name=\"c_clas1\")(capas_base)\n",
    "clasificacion=layers.Dense(10,name=\"cl_head\")(clasificacion) #10 neuronas, pues son 10 clases\n",
    "\n",
    "#Ahora, se definen las capas para predecir los bounding boxes a partir de la capa de flatten (igual que el paso anterior)\n",
    "boundingb=layers.Dense(128,activation=\"relu\",name=\"c_boundb1\")(capas_base)\n",
    "boundingb=layers.Dense(64,activation=\"relu\",name=\"c_boundb2\")(boundingb)\n",
    "boundingb=layers.Dense(32,activation=\"relu\",name=\"c_bound3\")(boundingb)\n",
    "boundingb=layers.Dense(4,activation=\"linear\",name=\"bb_head\")(boundingb) #4 neuronas que representan a los bounding boxes\n",
    "\n",
    "\n",
    "#Finalmente, se creará el modelo final con las 2 capas de salida (clasificación y bounding boxes)\n",
    "#Para ello, se deben 'unir' ambas ramas.\n",
    "modelo=tensorflow.keras.Model(input_layer,\n",
    "                              outputs=[clasificacion,boundingb])\n",
    "\n",
    "#Vemos la arquitectura del modelo\n",
    "modelo.summary()\n",
    "\n",
    "#Debido a que la red fue creada para dar como resultado 2 outputs, es necesario definir dos funciones de pérdida\n",
    "#para cada una de las ramas. Se usará \"Sparse Categorical Crossentropy\" para la clasificación, y \"Mean Squared Error\"\n",
    "#para los bounding. Se definirán en un diccionario (tiene que coincidir el head de las últimas capas)\n",
    "func_perd={\"cl_head\":tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           \"bb_head\":tensorflow.keras.losses.MeanSquaredError}\n",
    "\n",
    "#Se define el optimizador. En este caso, se usará \"Adam\"\n",
    "modelo.compile(loss=func_perd,optimizer=\"Adam\",\n",
    "               metrics={\"cl_head\":\"accuracy\",\n",
    "                        \"bb_head\":tensorflow.keras.metrics.MeanSquaredError()})\n",
    "\n",
    "#Primero, se crearán dos diccionarios, para almacenar los targets individuales (bounding boxes, y clases)\n",
    "train_targets={\n",
    "    \"cl_head\":ytrain_clase,\n",
    "    \"bb_head\":y_train\n",
    "}\n",
    "test_targets={\n",
    "    \"cl_head\":ytest_clase,\n",
    "    \"bb_head\":y_test\n",
    "}\n",
    "\n",
    "\n",
    "#Ahora, se procederá al entrenamiento del modelo. El número de épocas será 20 (aunque puede ser más, para mayor entrenamiento)\n",
    "#pero debido al tiempo que se demora para entrenar, se colocarán solo 20 épocas. El tamaño del batch será 4\n",
    "modelo.fit(x_train,train_targets,\n",
    "                validation_data=(x_test,test_targets),\n",
    "                batch_size=4,\n",
    "                epochs=2,\n",
    "                shuffle=True,\n",
    "                verbose=1)\n",
    "print(\"Se terminó de entrenar\")\n",
    "\n",
    "\n",
    "#Se realiza la predicción con algunos datos\n",
    "ejemplos=[3,13,20,6]\n",
    "ejemplos_a_predecir=[]\n",
    "\n",
    "#Se generan las gráficas para algunas imágenes y comprobar los valores predichos por el modelo\n",
    "import matplotlib.pyplot as plt #La librería matplotlib para mostrar las imágenes\n",
    "for ejm in ejemplos:\n",
    "  #Se genera la gráfica para cada imagen\n",
    "  img=x_test[ejm]\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "  #Se agregan las imágenes a la lista de \"ejemplos_a_predecir\"\n",
    "  ejemplos_a_predecir.append(x_test[ejm])\n",
    "\n",
    "#Se realiza la conversión a un arreglo de Numpy\n",
    "ejemplos_a_predecir=np.array(ejemplos_a_predecir)\n",
    "\n",
    "#Se generan las predicciones para cada imagen\n",
    "predicciones = modelo.predict(ejemplos_a_predecir)\n",
    "print(\"predicciones:\",predicciones)\n",
    "\n",
    "#Se usa la función argmax para obtener la clase solo con mayor probabilidad de ser\n",
    "clases=np.argmax(predicciones[0], axis = 1)\n",
    "print(clases)\n",
    "print(\"Diccionario:\",etiquetas) #Se imprime el diccionario para ver qué clase fue la que predijo el modelo"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
